{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Aug 10 19:29:11 2018\n",
    "\n",
    "@author: ankurs\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "def date_splitter(dateToSplit):\n",
    "    dateToSplit = dateToSplit.split('-', 1)\n",
    "    year = dateToSplit[0]\n",
    "    dateToSplit = dateToSplit[1].split('-', 1)\n",
    "    month = dateToSplit[0]\n",
    "    day = dateToSplit[1]\n",
    "    return year, month, day\n",
    "\n",
    "bdf = pd.read_excel('bangalore-cas-alerts.xlsx')\n",
    "\n",
    "bdf = bdf.rename(columns = {'deviceCode_time_recordedTime_$date':'timestamp'})\n",
    "bdf['timestamp'] = pd.to_datetime(bdf['timestamp'])\n",
    "bdf['eventDate'] = pd.to_datetime(bdf['timestamp'])\n",
    "bdf['eventDate'] = bdf['eventDate'].dt.strftime('%Y%m%d')\n",
    "bdf['e_hour'] = pd.to_datetime(bdf['timestamp'], format = '%H:%M:%S').dt.hour\n",
    "bdf['ehourCat'] = 0\n",
    "bdf['ehourCat'] = np.where((bdf['e_hour'] >= 0) & (bdf['e_hour'] < 6), 1, bdf['ehourCat'])\n",
    "bdf['ehourCat'] = np.where((bdf['e_hour'] >= 6) & (bdf['e_hour'] < 10), 2, bdf['ehourCat'])\n",
    "bdf['ehourCat'] = np.where((bdf['e_hour'] >= 10) & (bdf['e_hour'] < 16), 3, bdf['ehourCat'])\n",
    "bdf['ehourCat'] = np.where((bdf['e_hour'] >= 16) & (bdf['e_hour'] < 21), 4, bdf['ehourCat'])\n",
    "bdf['ehourCat'] = np.where((bdf['e_hour'] >= 21) & (bdf['e_hour'] < 24), 5, bdf['ehourCat'])\n",
    "bdf['weatherDate'] = bdf['eventDate']\n",
    "bdf['weatherDate'] = bdf['weatherDate'].astype(str)\n",
    "\n",
    "bwdf = pd.read_excel('bangalore-weather.xlsx')\n",
    "bwdf['w_hour'] = pd.to_datetime(bwdf['time'], format= '%H:%M').dt.hour\n",
    "bwdf['hourCat'] = 0\n",
    "bwdf['hourCat'] = np.where((bwdf['w_hour'] >= 0) & (bwdf['w_hour'] < 6), 1, bwdf['hourCat'])\n",
    "bwdf['hourCat'] = np.where((bwdf['w_hour'] >= 6) & (bwdf['w_hour'] < 10), 2, bwdf['hourCat'])\n",
    "bwdf['hourCat'] = np.where((bwdf['w_hour'] >= 10) & (bwdf['w_hour'] < 16), 3, bwdf['hourCat'])\n",
    "bwdf['hourCat'] = np.where((bwdf['w_hour'] >= 16) & (bwdf['w_hour'] < 21), 4, bwdf['hourCat'])\n",
    "bwdf['hourCat'] = np.where((bwdf['w_hour'] >= 21) & (bwdf['w_hour'] < 24), 5, bwdf['hourCat'])\n",
    "bwdf = bwdf.drop_duplicates(subset = ['weatherDate', 'hourCat'], keep = 'first')\n",
    "bwdf['ehourCat'] = bwdf['hourCat']\n",
    "bwdf['weatherDate'] = bwdf['weatherDate'].astype(str)\n",
    "\n",
    "b1 = pd.merge(bdf, bwdf, on = ['weatherDate', 'ehourCat'], how = 'left')\n",
    "b1 = b1.rename(columns = {'deviceCode_location_wardName':'Area'})\n",
    "badf = pd.read_excel('bangalore-accident-zones.xlsx')\n",
    "\n",
    "##################################################################################################\n",
    "#\n",
    "#                                               MAIN DATASET\n",
    "#\n",
    "##################################################################################################\n",
    "\n",
    "b = pd.merge(b1, badf, on = ['Area'], how = 'left')\n",
    "b = b.rename(columns = {'deviceCode_pyld_alarmType':'Alarm_Type'})\n",
    "b = b.rename(columns = {'deviceCode_pyld_speed':'Plying_Speed'})\n",
    "b['hasOversped'] = np.where(b.Plying_Speed > 60, 1, 0)\n",
    "b['hasOversped'] = np.where(b.Alarm_Type == 'Overspeed', 1, b['hasOversped'])\n",
    "\n",
    "for column in ['temperature', 'visibility', 'condition']:\n",
    "    b[column].fillna(b[column].mode()[0], inplace=True)\n",
    "\n",
    "b['visibility'] = np.where(b['visibility'] < 10, 0, 1)\n",
    "\n",
    "df = b.copy()\n",
    "df['hasOversped'] = np.where(b.hasOversped == 1, 'Yes', 'No')\n",
    "df['visibility'] = np.where(b.visibility == 0, 'Low', 'High')\n",
    "df['ehourCat'] = b['ehourCat'].map({1: 'Early', 2: 'PeakM', 3: 'RegularM'})\n",
    "b['Accident_Severity'] = b['Accident_Severity'].map({'High': 3, 'Medium': 2, 'Low': 1})\n",
    "b['Pothole_Severity'] = b['Pothole_Severity'].map({'High': 3, 'Medium': 2, 'Low': 1})\n",
    "b['Alarm_Type'] = b['Alarm_Type'].map({'PCW': 1, 'FCW': 2, 'Overspeed': 3, 'HMW': 4, 'UFCW': 5, 'LDWL': 6, 'LDWR': 7})\n",
    "b['condition'] = b['condition'].map({'Clear': 1, 'Sunny': 2, 'Passing clouds': 3,\n",
    "       'Broken clouds': 4, 'Scattered clouds': 5, 'Fog': 6, 'Haze': 7, 'Partly cloudy': 8,\n",
    "       'Mild': 9, 'Drizzle. Broken clouds': 10})\n",
    "b['Area'] = b['Area'].map({'Kadugodi': 1, 'Garudachar Playa': 2, 'Hudi': 3, 'Other': 4, 'Devasandra': 5,\n",
    "       'Hagadur': 6, 'Bellanduru': 7, 'Marathahalli': 8, 'Dodda Nekkundi': 9, 'Varthuru': 10,\n",
    "       'HAL Airport': 11, 'Vijnana Nagar': 12, 'Konena Agrahara': 13, 'A Narayanapura': 14,\n",
    "       'C V Raman Nagar': 15, 'Jeevanbhima Nagar': 16, 'HSR Layout': 17, 'Domlur': 18, 'Jogupalya': 19,\n",
    "       'Hoysala Nagar': 20, 'New Tippasandara': 21, 'Benniganahalli': 22, 'Singasandra': 23,\n",
    "       'Basavanapura': 24, 'Halsoor': 25, 'Agaram': 26, 'Shantala Nagar': 27, 'Sampangiram Nagar': 28,\n",
    "       'Sudham Nagara': 29, 'Dharmaraya Swamy Temple': 30, 'Chickpete': 31, 'Banasavadi': 32,\n",
    "       'Horamavu': 33, 'Kacharkanahalli': 34, 'Kammanahalli': 35, 'Vijnanapura': 36, 'Ramamurthy Nagar': 37,\n",
    "       'K R Puram': 38, 'BTM Layout': 39, 'Madivala': 40, 'Gurappanapalya': 41, 'J P Nagar': 42, 'Sarakki': 43,\n",
    "       'Jaraganahalli': 44, 'Vasanthpura': 45, 'Hemmigepura': 46, 'Yelchenahalli': 47,\n",
    "       'Jayanagar East': 48, 'Bharathi Nagar': 49, 'other': 4})\n",
    "\n",
    "writer = ExcelWriter('bangalore-consolidated-data.xlsx')\n",
    "b.to_excel(writer, index = False, sheet_name = 'Sheet1')\n",
    "df.to_excel(writer, index = False, sheet_name = 'Sheet2')\n",
    "writer.save()\n",
    "\n",
    "del b['deviceCode_deviceCode'], b['deviceCode_location_latitude'], b['deviceCode_location_longitude']\n",
    "del b['w_hour'], b['Mapped_Location'], b['timestamp'], b['e_hour'], b['weatherDate']\n",
    "del b['hourCat'], b['time'], b['temperature'], b['eventDate'], b['Plying_Speed']\n",
    "\n",
    "del df['deviceCode_deviceCode'], df['deviceCode_location_latitude'], df['deviceCode_location_longitude']\n",
    "del df['w_hour'], df['Mapped_Location'], df['timestamp'], df['e_hour'], df['weatherDate']\n",
    "del df['hourCat'], df['time'], df['temperature'], df['eventDate'], df['Plying_Speed']\n",
    "\n",
    "del bwdf, b1, badf, bdf\n",
    "\n",
    "##################################################################################################\n",
    "#\n",
    "#                                       CLUSTERING ALGORITHMS\n",
    "#\n",
    "##################################################################################################\n",
    "\n",
    "##### NUMERICAL DATA INPUT #######\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = b.values.astype(np.float)\n",
    "kmeans = KMeans(n_clusters = 2, max_iter = 1000).fit(X)\n",
    "kmlabels = kmeans.labels_\n",
    "kmlabels = kmlabels.tolist()\n",
    "print('Finished clustering using K-Means')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = b.values.astype(np.float)\n",
    "kmeans = KMeans(n_clusters = 2, max_iter = 1000, algorithm = 'full').fit(X)\n",
    "kmflabels = kmeans.labels_\n",
    "kmflabels = kmflabels.tolist()\n",
    "print('Finished clustering using K-Means')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = b.values.astype(np.float)\n",
    "kmeans = KMeans(n_clusters = 2, max_iter = 2000, algorithm = 'full').fit(X)\n",
    "kmf2labels = kmeans.labels_\n",
    "kmf2labels = kmf2labels.tolist()\n",
    "print('Finished clustering using K-Means')\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "###### BINARY NUMERICAL DATA INPUT ##########\n",
    "\n",
    "x = pd.get_dummies(data = df, columns = df.columns.values.tolist())\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = x.values.astype(np.float)\n",
    "kmeans = KMeans(n_clusters = 2, max_iter = 1000).fit(X)\n",
    "dkmlabels = kmeans.labels_\n",
    "dkmlabels = dkmlabels.tolist()\n",
    "print('Finished clustering using K-Means')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = x.values.astype(np.float)\n",
    "kmeans = KMeans(n_clusters = 2, max_iter = 1000, algorithm = 'full').fit(X)\n",
    "dkmflabels = kmeans.labels_\n",
    "dkmflabels = dkmflabels.tolist()\n",
    "print('Finished clustering using K-Means')\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = x.values.astype(np.float)\n",
    "kmeans = KMeans(n_clusters = 2, max_iter = 2000, algorithm = 'full').fit(X)\n",
    "dkmf2labels = kmeans.labels_\n",
    "dkmf2labels = dkmf2labels.tolist()\n",
    "print('Finished clustering using K-Means')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps = 2.5, min_samples = 2, algorithm = 'auto').fit(X)\n",
    "dblabels = db.labels_\n",
    "dblabels = dblabels.tolist()\n",
    "print('Finished clustering using DBSCAN')\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "sc = SpectralClustering(n_clusters = 2).fit(X)\n",
    "sclabels = sc.labels_\n",
    "sclabels = sclabels.tolist()\n",
    "print('Finished clustering using Spectral Clustering')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from sklearn.cluster import Birch\n",
    "birch = Birch(threshold = 0.5, branching_factor = 50, n_clusters = 2).fit(X)\n",
    "birchlabels = birch.labels_\n",
    "birchlabels = birchlabels.tolist()\n",
    "print('Finished clustering using Birch')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "fa = FeatureAgglomeration(n_clusters = 2, affinity='euclidean').fit(X)\n",
    "falabels = fa.labels_\n",
    "falabels = falabels.tolist()\n",
    "print('Finished clustering using Feature Agglomeration')\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ac = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean').fit(X)\n",
    "aclabels = ac.labels_\n",
    "aclabels = aclabels.tolist()\n",
    "print('Finished clustering using Agglomerative Clustering').fit(X)\n",
    "\"\"\"\n",
    "\n",
    "newDf = pd.DataFrame()\n",
    "#newDf['Birch'] = birchlabels\n",
    "newDf['Kmeans'] = kmlabels\n",
    "newDf['EMKmeans'] = kmflabels\n",
    "newDf['EM2Kmeans'] = kmf2labels\n",
    "newDf['DKmeans'] = dkmlabels\n",
    "newDf['DEMKmeans'] = dkmflabels\n",
    "newDf['DEM2Kmeans'] = dkmf2labels\n",
    "\n",
    "end_time = time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"\\nTotal time taken in seconds: \", time_taken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
